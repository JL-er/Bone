  0%|                                                                                                                                                                                                                                                                                                  | 0/3125 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/rwkv/JL/GMM/llama/gmm.py", line 300, in <module>
    train()
  File "/home/rwkv/JL/GMM/llama/gmm.py", line 289, in train
    trainer.train(resume_from_checkpoint = resume_from_checkpoint_dir)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 1938, in train
    return inner_training_loop(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 2279, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 3318, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 3363, in compute_loss
    outputs = model(**inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    loss = self.module(*inputs, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py", line 1026, in forward
    outputs = self.model(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py", line 830, in forward
    layer_outputs = decoder_layer(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py", line 552, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py", line 448, in forward
    query_states = self.q_proj(hidden_states)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/JL/GMM/llama/gmmLinear.py", line 97, in forward
    return F.linear(x, self.weight.data) + ic
RuntimeError: The size of tensor a (512) must match the size of tensor b (32) at non-singleton dimension 2
Traceback (most recent call last):
  File "/home/rwkv/JL/GMM/llama/gmm.py", line 300, in <module>
    train()
  File "/home/rwkv/JL/GMM/llama/gmm.py", line 289, in train
    trainer.train(resume_from_checkpoint = resume_from_checkpoint_dir)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 1938, in train
    return inner_training_loop(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 2279, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 3318, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 3363, in compute_loss
    outputs = model(**inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    loss = self.module(*inputs, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py", line 1026, in forward
    outputs = self.model(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py", line 830, in forward
    layer_outputs = decoder_layer(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py", line 552, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py", line 448, in forward
    query_states = self.q_proj(hidden_states)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/JL/GMM/llama/gmmLinear.py", line 97, in forward
    return F.linear(x, self.weight.data) + ic
RuntimeError: The size of tensor a (512) must match the size of tensor b (32) at non-singleton dimension 2