  0%|                                                                                                                                                                                                                                                                             | 0/3125 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/einops/einops.py", line 413, in reduce
    return _apply_recipe(recipe, tensor, reduction_type=reduction)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/einops/einops.py", line 236, in _apply_recipe
    _reconstruct_from_shape(recipe, backend.shape(tensor))
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/einops/einops.py", line 201, in _reconstruct_from_shape_uncached
    raise EinopsError("Shape mismatch, can't divide axis of length {} in chunks of {}".format(
einops.EinopsError: Shape mismatch, can't divide axis of length 32 in chunks of 64
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/rwkv/JL/GMM/llama/gmm.py", line 301, in <module>
    train()
  File "/home/rwkv/JL/GMM/llama/gmm.py", line 290, in train
    trainer.train(resume_from_checkpoint = resume_from_checkpoint_dir)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 1938, in train
    return inner_training_loop(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 2279, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 3318, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 3363, in compute_loss
    outputs = model(**inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    loss = self.module(*inputs, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/peft/peft_model.py", line 1577, in forward
    return self.base_model(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 188, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 1054, in forward
    outputs = self.model(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 856, in forward
    layer_outputs = decoder_layer(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 596, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 483, in forward
    query_states = self.q_proj(hidden_states)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/peft/tuners/lora/layer.py", line 556, in forward
    result = result + lora_B(lora_A(dropout(x))) * scaling
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/JL/GMM/llama/gmmLinear.py", line 108, in forward
    w = rearrange(self.weight, '(a r1) (b r2) -> b a r1 r2', r1 = self.r, r2 = self.r)@self.gbmm.reshape(self.out_features//self.r, self.r, -1)+self.gbmm.reshape(self.out_features//self.r, self.r, -1)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/einops/einops.py", line 484, in rearrange
    return reduce(tensor, pattern, reduction='rearrange', **axes_lengths)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/einops/einops.py", line 421, in reduce
    raise EinopsError(message + '\n {}'.format(e))
einops.EinopsError:  Error while processing rearrange-reduction pattern "(a r1) (b r2) -> b a r1 r2".
 Input tensor shape: torch.Size([32, 1536]). Additional info: {'r1': 64, 'r2': 64}.
 Shape mismatch, can't divide axis of length 32 in chunks of 64
Traceback (most recent call last):
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/einops/einops.py", line 413, in reduce
    return _apply_recipe(recipe, tensor, reduction_type=reduction)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/einops/einops.py", line 236, in _apply_recipe
    _reconstruct_from_shape(recipe, backend.shape(tensor))
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/einops/einops.py", line 201, in _reconstruct_from_shape_uncached
    raise EinopsError("Shape mismatch, can't divide axis of length {} in chunks of {}".format(
einops.EinopsError: Shape mismatch, can't divide axis of length 32 in chunks of 64
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/rwkv/JL/GMM/llama/gmm.py", line 301, in <module>
    train()
  File "/home/rwkv/JL/GMM/llama/gmm.py", line 290, in train
    trainer.train(resume_from_checkpoint = resume_from_checkpoint_dir)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 1938, in train
    return inner_training_loop(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 2279, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 3318, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 3363, in compute_loss
    outputs = model(**inputs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    loss = self.module(*inputs, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/peft/peft_model.py", line 1577, in forward
    return self.base_model(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 188, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 1054, in forward
    outputs = self.model(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 856, in forward
    layer_outputs = decoder_layer(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 596, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 483, in forward
    query_states = self.q_proj(hidden_states)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/peft/tuners/lora/layer.py", line 556, in forward
    result = result + lora_B(lora_A(dropout(x))) * scaling
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rwkv/JL/GMM/llama/gmmLinear.py", line 108, in forward
    w = rearrange(self.weight, '(a r1) (b r2) -> b a r1 r2', r1 = self.r, r2 = self.r)@self.gbmm.reshape(self.out_features//self.r, self.r, -1)+self.gbmm.reshape(self.out_features//self.r, self.r, -1)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/einops/einops.py", line 484, in rearrange
    return reduce(tensor, pattern, reduction='rearrange', **axes_lengths)
  File "/home/rwkv/miniconda3/lib/python3.10/site-packages/einops/einops.py", line 421, in reduce
    raise EinopsError(message + '\n {}'.format(e))
einops.EinopsError:  Error while processing rearrange-reduction pattern "(a r1) (b r2) -> b a r1 r2".
 Input tensor shape: torch.Size([32, 1536]). Additional info: {'r1': 64, 'r2': 64}.
 Shape mismatch, can't divide axis of length 32 in chunks of 64